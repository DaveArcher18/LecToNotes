# LecToNotes Output Description

This document provides a comprehensive description of the output files generated by the LecToNotes system, including their locations, formats, and schemas.

## Output Directory Structure

All output files are stored in a directory named `<TITLE> OUTPUT`, where `<TITLE>` is the lecture title specified when running the system. The directory structure is as follows:

```
<TITLE> OUTPUT/
├── transcript.json         # Extracted transcript
├── boards/                 # Directory containing board images
│   ├── board_*.jpg         # Extracted board images
│   └── boards.json         # Metadata for board images
└── merge/                  # Directory containing merged content
    └── lecture.json        # Final unified lecture content
```

## JSON File Schemas

### 1. `transcript.json`

This file contains the timestamped segments of the lecture transcript, extracted from the video.

**Schema:**
```json
[
  {
    "start": "HH_MM_SS",      // Start timestamp (format: hours_minutes_seconds)
    "end": "HH_MM_SS",        // End timestamp (format: hours_minutes_seconds)
    "content": "string"      // Transcribed speech content for this segment
  },
  ...
]
```

**Example:**
```json
[
  {
    "start": "00_00_00",
    "end": "00_05_00",
    "content": "So I want to talk in this course about something that I call a Habiro cohomology..."
  },
  {
    "start": "00_05_00",
    "end": "00_10_00",
    "content": "So I have to watch the lectures from last year..."
  }
]
```

### 2. `boards/boards.json`

This file contains metadata for the blackboard images extracted from the video, including timestamps, file paths, and OCR-processed text content (typically in LaTeX format).

**Schema:**
```json
[
  {
    "timestamp": "HH_MM_SS",  // Timestamp when the board appears (format: hours_minutes_seconds)
    "path": "string",        // Relative path to the board image file
    "text": "string"        // OCR-processed text content of the board (often in LaTeX format)
  },
  ...
]
```

**Example:**
```json
[
  {
    "timestamp": "00_03_24",
    "path": "boards/board_00_03_24_000.jpg",
    "text": "\\begin{center}\nNo Lecture next two weeks (Easter Holidays)\n\\end{center}\nNext Lecture: May 2\n\n\\textbf{Habiro Cohomology}\n\n..."
  },
  {
    "timestamp": "00_09_51",
    "path": "boards/board_00_09_51_000.jpg",
    "text": "% illegible"
  }
]
```

### 3. `merge/lecture.json`

This is the final unified representation of the lecture content, combining the transcript and board images into time-segmented chunks.

**Schema:**
```json
{
  "lecture": "string",       // Lecture title
  "date": "YYYY-MM-DD",     // Lecture date (optional, if provided)
  "segments": [             // Array of time-segmented lecture content
    {
      "start_time": "HH:MM:SS",      // Segment start time (format: hours:minutes:seconds)
      "end_time": "HH:MM:SS",        // Segment end time (format: hours:minutes:seconds)
      "spoken_content": "string",    // Transcribed speech for this time segment
      "written_content": [           // Array of board contents visible during this segment
        {
          "timestamp": "HH_MM_SS",    // Board timestamp
          "path": "string",          // Path to board image
          "text": "string"          // OCR-processed text from the board
        },
        ...
      ]
    },
    ...
  ]
}
```

**Example:**
```json
{
  "lecture": "habiro_cohomology_1",
  "segments": [
    {
      "start_time": "00:00:00",
      "end_time": "00:05:00",
      "spoken_content": "So I want to talk in this course about something that I call a Habiro cohomology...",
      "written_content": [
        {
          "timestamp": "00_03_24",
          "path": "boards/board_00_03_24_000.jpg",
          "text": "\\begin{center}\nNo Lecture next two weeks (Easter Holidays)\n\\end{center}\n..."
        }
      ]
    },
    ...
  ]
}
```

## Processing Flow

1. **Transcript Extraction**: The system extracts the transcript from the video, segmenting it into time intervals (default: 5 minutes).

2. **Board Extraction**: The system extracts blackboard images from the video at key frames where content changes.

3. **OCR Processing**: The extracted board images are processed with OCR to convert the visual content into text (often preserving LaTeX formatting).

4. **Merging**: The transcript segments and board images are merged into a unified representation based on their timestamps, creating the final `lecture.json` file.

## Timestamp Formats

The system supports two timestamp formats:

1. **Underscore format** (`HH_MM_SS`): Used in input files like `boards.json` and `transcript.json`.
2. **Colon format** (`HH:MM:SS`): Used in the final merged output (`lecture.json`).

The system automatically normalizes between these formats during processing.

## Configuration Options

When generating output, several configuration options can be specified:

- **TITLE**: The lecture title (default: "Untitled Lecture")
- **DATE**: The lecture date in YYYY-MM-DD format (optional)
- **INTERVAL**: The time interval for segmentation in seconds (default: 300 seconds / 5 minutes)
- **USE_GROQ**: Whether to use the Groq API for transcription (default: false)

These options affect how the output files are generated and organized.