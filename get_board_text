import cv2
import os
import json
import argparse
import numpy as np

# --- Argument parser ---
parser = argparse.ArgumentParser(description="Detect and crop full blackboards from a lecture video.")
parser.add_argument("video_path", type=str, help="Path to the input .mp4 video file")
args = parser.parse_args()

# --- Configuration ---
frame_interval_sec = 3  # adjust based on lecture speed
output_dir = "cropped_text_regions"
os.makedirs(output_dir, exist_ok=True)

# --- Extract frames ---
cap = cv2.VideoCapture(args.video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
interval = int(fps * frame_interval_sec)
frame_num = 0
regions_data = []

while True:
    ret, frame = cap.read()
    if not ret:
        break
    if frame_num % interval == 0:
        timestamp = round(frame_num / fps, 2)

        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Edge detection for board shape detection
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        edges = cv2.Canny(blurred, 50, 150)

        # Find contours to detect rectangular shapes (like blackboards)
        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        possible_boards = []

        for cnt in contours:
            approx = cv2.approxPolyDP(cnt, 0.02 * cv2.arcLength(cnt, True), True)
            if len(approx) == 4 and cv2.isContourConvex(approx):
                x, y, w, h = cv2.boundingRect(approx)
                aspect_ratio = w / float(h)
                area = w * h
                if area > 150000 and 1.0 < aspect_ratio < 3.5:  # Heuristic for board size/shape
                    possible_boards.append((x, y, w, h))

        if possible_boards:
            # Choose the largest candidate
            board = max(possible_boards, key=lambda b: b[2]*b[3])
            x, y, w, h = board
            cropped = frame[y:y+h, x:x+w]
            crop_path = os.path.join(output_dir, f"frame_{frame_num}_blackboard.jpg")
            cv2.imwrite(crop_path, cropped)

            regions_data.append({
                "timestamp": timestamp,
                "frame": frame_num,
                "crop_path": crop_path,
                "width": w,
                "height": h
            })

    frame_num += 1

cap.release()

# --- Save to JSON ---
output_json = "cropped_regions.json"
with open(output_json, "w", encoding="utf-8") as f:
    json.dump(regions_data, f, indent=2, ensure_ascii=False)
print(f"\nâœ… Saved cropped regions metadata to: {output_json}")
